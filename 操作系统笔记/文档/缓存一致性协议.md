[TOC]

## 一、CPU高速缓存

![8](D:\notes\操作系统笔记\资源\8.jpg)

CPU高速缓存是位于CPU与内存之间的临时存储器，主要是为了解决CPU运行处理速度与内存读写速度不匹配的矛盾；

CPU在执行指令时需要从内存获取指令和所需的数据，但是CPU的速度远远大于内存速度，所以CPU直接从内存中取数据需要等待一段时间，造成资源的浪费并影响性能；

这时CPU引入了缓存机制，现在常见的CPU都采用的三级缓存结构，CPU缓存被分成了三个级别：L1、L2、L3，级别越小越接近CPU，所以速度也更快，同时也代表容量越小。

CPU往往需要重复相同的数据、指令，把这部份数据、指令放在CPU缓存中，CPU就不需要从内存中读取数据、指令，从而减少了响应时间，体现了局部性原理。

局部性原理：

- 时间局部性原理：如果某个数据被访问，那么不久的将来它可能再次被访问；
- 空间局部性原理：如果某个数据被访问，那么与它相邻的数据也可能很快被访问。

CPU缓存是由一组称之为缓存行的固定大小的数据块组成的，缓存行是缓存中可以分配的最小存储单位，通常是64字节；

但是引入了缓存，就需要考虑缓存一致性问题。

## 二、缓存一致性

CPU引入了高速缓存后提升了效率，但是同时也会引发缓存与主存不一致的问题。

对于单核CPU来说，通常有两种方式：

- 通写法(Write Through)：每次CPU修改了缓存内容，立即更新到内存，也就意味着每次 CPU 写共享数据，都会导致总线事务；
- 回写法(Write BACK)：每次CPU修改了缓存数据，不会立即更新到内存，而是等到某个合适的时机才会更新到内存中去。

对于多核 CPU 来说，情况会更为复杂，如下图：

![9](D:\notes\操作系统笔记\资源\9.jpg)

多核CPU存在多个一级缓存，为了保证缓存以及内存之间的一致性又引入了两种操作：

- 写失效：当一个 CPU 修改了数据，如果其他CPU有该数据，则通知其为无效；
- 写更新：当一个 CPU 修改了数据，如果其他CPU有该数据，则通知其更新数据。

另外在 CPU 层面，提供了两种解决方案：

- 总线锁：在多CPU情况下，某个CPU对共享变量操作时，在总线上发出一个`#LOCK`信号，总线把CPU和内存之间的通信锁住了，其它CPU不能操作该内存地址的数据；
- 缓存锁：降低了锁的粒度，基于缓存一致性协议来实现。

缓存一致性协议需要满足以下两种特性：

- 写传播(Write propagation)：一个处理器对于某个内存位置所做的写操作，对于其他处理器是可见的；
- 写串行化(Write Serialization)：对同一内存单元的所有写操作都能串行化。即所有的处理器能以相同的次序看到这些写操作

对于写串行化：总线上任意时间只能出现一个 CPU 的写事件，多核并发的写事件会通过总线仲裁机制将其转换成串行化的的写事件序列。

对于写传播大致可以分为以下两种方式：

- 嗅探(Snooping )：广播机制，即要监听总线上的所有活动。
- 基于目录(Directory-based)：点对点，总线事件只会发给感兴趣的 CPU (借助 directory)。

缓存一致性协议通常指的是：MESI协议。

## 三、MESI缓存一致性协议

![10](D:\notes\操作系统笔记\资源\10.jpg)

### 3.1、四种状态

MESI 指的是缓存行的四种状态（Modified，Exclusive，Shared， Invalid），用 2 个 bit 表示。

- M: 被修改（Modified)

当前 CPU 缓存有最新数据， 其他 CPU 拥有失效数据，当前 CPU 数据与内存不一致，但以当前 CPU 数据为准；

- E: 独享的（Exclusive)

只有当前 CPU 有数据，其他 CPU 没有该数据，当前 CPU 数据与内存数据一致；

- S: 共享的（Shared)

当前 CPU 与其他 CPU 拥有相同数据，并与内存中数据一致；

- I: 无效的（Invalid）

当前 CPU 数据失效，其他 CPU 数据可能有可能无，数据应从内存中读取，且当前 CPU 与 内存数据不一致。

### 3.2、四种操作

- Local Read（LR）：当前 CPU 读操作；
- Local Write（LW）：当前 CPU 写操作；
- Remote Read（RR）：其他 CPU 读操作；
- Remote Write（RW）：其他 CPU 写操作。

#### 3.2.1、Modified被修改

- LR（当前 CPU 读操作）：缓存中拥有最新数据，直接从缓存中读取，状态不变；
- LW（当前 CPU 写操作）：直接修改当前 CPU 缓存数据，修改后仍拥有最新数据，状态不变；
- RR（其他 CPU 方式读操作）：为了保证一致性，当前 CPU 将数据写回内存，随后 RR 使得其他 CPU 与当前 CPU 拥有相同数据，状态改为 S 共享状态；
- RW（其他 CPU 写操作）：当前 CPU 将数据写回内存，随后 RW 将内存数据修改，当前 CPU 缓存状态改为 I失效状态。

#### 3.2.2、Exclusive独享的

- LR：当前 CPU 读操作，状态不变；
- LW：当前 CPU 写操作，修改当前 CPU 缓存值，状态改为 M 被修改状态；
- RR：其他 CPU 读操作，两个 CPU 和内存中数据一致，状态改为 S 共享状态；
- RW：其他 CPU 写操作，其他 CPU 数据为最新，当前 CPU 数据失效，状态改为 I 失效状态。

#### 3.2.3、Shared共享状态

- LR：当前 CPU 读数据，状态不变；
- LW：当前 CPU 写操作，并不会将数据立即写回内存，为了保证一致性，将状态修改为 M 被修改状态；
- RR：其他 CPU 读操作，因为多个 CPU 数据都与内存一致，状态不变；
- RW：其他 CPU 写操作，其他 CPU 数据为最新，当前 CPU 数据失效，状态改为 I 失效状态。

#### 3.2.4、Invalid失效状态

- LR：当前 CPU 读操作，当前 CPU 缓存不可用，需要读内存
- - 其他 CPU 无数据，当前 CPU 独享数据，状态改为 E
  - 其他 CPU 有数据且状态为 S 、E，当前CPU 与其他 CPU 以及内存数据一致，状态修改为 S
  - 其他 CPU 有数据且状态为 M, 其他 CPU 先将数据写回内存，随后当前 CPU 读数据，与其他 CPU 以及内存数据一致，状态改为 S
- LW：当前 CPU 写操作，当前 CPU 缓存不可用，需要写内存
- - 其他 CPU 无数据，只有当前 CPU 缓存有数据，且被修改与内存不一致，状态改为 M
  - 其他 CPU 又数据且为 S、E，当前 CPU 缓存为最新且已修改，状态改为 M
  - 其他 CPU 有数据且状态为 M, 其他 CPU 先将数据写回内存，随后当前 CPU 写数据，状态改为 M
- RR：其他 CPU 读操作，与当前 CPU 缓存无关，状态不变
- RW：其他 CPU 写操作，与当前 CPU 缓存无关，状态不变

## 四、MESI协议的问题与优化

在 MESI 中，依赖总线嗅探机制，整个过程是串行的，可能会发生阻塞。

1. 若 CPU0 发生 LW，首先需要发送一个 Invalidate 消息给到其他缓存了该数据的 CPU1。并且要等待 CPU1 的确认回执，CPU0 在这段时间内都会处于阻塞状态；
2. 对于 CPU1 发生 RW，需要失效缓存。当其高速缓存压力很大时，要求实时的处理失效事件也存在一定的困难，会有一定的延迟。

所以为了解决上面两个问题，引入了写缓冲区（Load Buffer）和失效队列（Invalid Queue）。

#### 4.1、写缓冲区（Load Buffer）

写缓冲区是属于每个 CPU 的，当使用了写缓冲区后，每当发生 LW，当前 CPU 不再阻塞地等待其他 CPU 的确认回执，而是直接将更新的值直接写入写缓冲区，然后继续执行后续指令；

在进行 LR 时，CPU 会先在写缓冲区中查询记录是否存在，如果存在则会从写缓冲区中直接获取，这一机制即是 Store Fowarding。

#### 4.2、失效队列（Invalid Queue）

失效队列也是属于每个 CPU，使用失效队列后，发生 RW 对应的 CPU 缓存不再同步地失效缓存并发送确认回执，而是将失效消息放入失效队列，立即发送确认回执；

后续 CPU 会在空闲是对失效队列中的消息进行处理，将对应的 CPU 缓存失效。

#### 4.3、优化后问题

引入 Load Buffer 后，即使读写指令本身是按照顺序执行的，但最终仍然可能会乱序执行。

例如：按顺序执行 A, B 两个写指令，A 写指令所在缓存行处于 S 状态，B 写指令所在缓存行处于E状态，那么 B 会比 A 先完成写入操作；又或者按顺序执行 C, D 两个读指令，C 读指令所在缓存行处于 I 状态，D 读指令所在缓存行处于 S 状态，那么 D 会比 C 先完成读取操作。

引入 Invalid Queue 后，可能会读取到过时的数据。

例如：CPU0 执行写指令，它向 CPU1 发出失效指令，然后 CPU1 立刻返回失效确认，但实际上并未真正执行失效操作，这时 CPU0 则更新了缓存行，造成了不同处理器直接的数据不一致。

#### 4.4、CPU内存屏障

MESI 原本是强一致性的，经过性能优化后，弱化成了最终一致性，在某些中间状态下，多个 CPU 之间的数据并不一致，同时也可能会发生乱序执行的情况，也就是重排序。

一般来说重排序分为以下三种：

1. 编译器优化的重排序：编译器在不改变单线程程语义的前提下，可以重新安排语句的执行顺序。
2. 指令级并行的重排序：现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP），将多条指令重叠执行；如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3. 内存系统的重排序：由于处理器使用缓存和读/写缓冲区，使得加载和存储过程看上去是在乱序执行。

第一种属于编译器重排序，后两种属于处理器重排序。

我们可以用内存屏障（Memory Barriers）去解决上面的一致性问题：

- 写屏障（Store Memory Barrier）：告诉 CPU 在执行屏障之后的指令前，将所有在存储缓存（store buffer）中的数据同步到内存；
- 读屏障（Load Memory Barrier）：告诉 CPU 在执行任何的加载前，先处理所有在失效队列（Invalid）中的消息。

但是 CPU 没办法自己判断应在何时何地添加内存屏障，它把决定权交给了软件应用层面，我们通常使用汇编指令 `LOCK` 做相应的处理。

`LOCK 指令前缀`有以下两大作用：

1. 开启总线锁或者缓存锁（通过在总线上发送 `#LOCK` 信号，联系上文所说，这里的缓存锁一般就是缓存一致性协议实现的）；
2. 与被修饰的汇编指令一起提供内存屏障的效果。

这样我们就在 CPU 层面，保证了多核 CPU 缓存的一致性。
